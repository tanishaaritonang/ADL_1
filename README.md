# ğŸ§  Adaptive Computer Network Learning Platform  

## ğŸ“˜ Overview  
A full-stack adaptive learning platform designed to help students master computer networking through AI-generated, personalized learning paths.  

All content, quizzes, and feedback â€” from pre-test to post-test â€” are generated dynamically by a fine-tuned AI model and grounded with RAG (Retrieval-Augmented Generation) via Supabase for factual accuracy and contextual relevance.  

The system automatically evaluates each learnerâ€™s level (*Easy*, *Medium*, *High*) and provides real-time AI feedback per question, creating a personalized and interactive learning experience.

---

## ğŸ—ï¸ Tech Stack  

### Frontend  
- Framework: Next.js 14 (App Router)  
- Styling: Tailwind CSS  
- UI Components: shadcn/ui  

### Backend  
- Server: Next.js API Routes  
- Database & RAG: Supabase (PostgreSQL + `pgvector`)  
- Containerization: Docker  

### AI/ML  
- Core Model: DeepSeek R1 Distill Qwen 1.5B (fine-tuned for educational assessment and feedback) used by using prompt engineering
- RAG System: Context-aware retrieval of factual learning content through Supabase  
- Model Serving: Ollama (local inference for fast, private generation)  

---

## ğŸš€ Core Features  

### ğŸ§‘â€ğŸ“ Student Experience  
- Module Selection: Choose networking topics (e.g., OSI Model, Subnetting, Routing).  
- Pre-Test (30 Questions):  
  - Automatically generated by AI using RAG context.  
  - Immediate feedback after each question:  
    - Indicates correctness (âœ… / âŒ)  
    - Provides a short explanation  
    - Cites the source (*Refs*) from RAG  
- AI-Determined Level Placement:  
  - Based on pre-test performance.  
  - Levels: *Easy*, *Medium*, *High*.  
- Adaptive Learning Path:  
  - AI generates level-appropriate materials and 10â€“15 practice questions.  
  - Each question includes instant feedback and references.  
- Post-Test (30 Questions):  
  - Level-matched exam to fairly measure mastery.  
  - Each question includes AI-generated feedback and RAG citations.  
- Final AI Feedback Summary:  
  - Personalized report including:  
    - Scores and level achieved  
    - Strengths and weaknesses  
    - Recommended next steps  
    - List of referenced sources (from RAG retrieval)  

---

## ğŸ‘¨â€ğŸ« Instructor Features  
- Monitor Progress: Track student performance, pre/post-test results, and progress per topic.  
- Simplified Analytics Dashboard:  
  - Class-wide statistics  
  - Learning gains  
  - Topic difficulty trends  
- Transparency: Every AI-generated question and explanation includes its source references from RAG.  

---

## ğŸ¤– AI Integration  

- Full AI Automation:  
  - Pre-test, module content, practice quizzes, post-test, and feedback are generated entirely by AI.  
- RAG Contextual Grounding (via Supabase):  
  - AI retrieves top contextual documents using `pgvector` embeddings stored in Supabase.  
  - Prevents hallucination and ensures every explanation is sourced from real material.  
- AI Feedback Loop:  
  - Feedback is generated both per question and at the end of each module.  
  - End feedback summarizes progress, weaknesses, and suggested learning paths.  
- Local Model Serving:  
  - Using Ollama for privacy-preserving inference with minimal latency.  

---

## ğŸ—„ï¸ Database Schema (Conceptual Overview)  

Supabase (PostgreSQL + `pgvector`) manages both user data and retrieval documents.  

### Key Entities  
- profiles â€“ user and instructor information (linked to Supabase Auth)  
- modules â€“ list of networking learning modules  
- placements â€“ AI-assigned difficulty level per student per module  
- attempts â€“ records of pre-test, practice, and post-test attempts  
- items â€“ stores each question, options, correct answer, explanation, and RAG references  
- rag_documents â€“ source materials for retrieval (e.g., textbooks, lecture notes, RFCs)  
- rag_chunks â€“ embedded vector chunks for RAG similarity search (`pgvector`)  

### Schema Highlights  
- RAG Grounding: `rag_chunks` enable precise retrieval of relevant text for AI context.  
- Question Feedback: Each `item` record contains per-question feedback and references.  
- Adaptive Placement: `placements` table automatically updates after pre-test completion.  

---

## ğŸ” Adaptive Learning Flow  

| Phase | Description | AI Role | RAG Role | Output |
|-------|--------------|----------|----------|--------|
| Pre-Test | 30 questions | Generate questions & assess responses | Retrieve contextual info | Level placement |
| Lesson | Learning materials + examples | Summarize key topics | Supply factual segments | Adaptive lessons |
| Practice | 10â€“15 questions | Generate practice exercises & explanations | Retrieve examples and notes | Reinforcement |
| Post-Test | 30 questions | Evaluate mastery | Contextual retrieval | Final assessment |
| Feedback | Summary report | Identify strengths, weaknesses, recommendations | Cite references | Personalized insights |

---

## ğŸ’¬ Example of AI Feedback per Question  

Question:  
> Which OSI layer handles data segmentation for transmission?  

Your Answer: Transport  

âœ… Correct!  
The Transport layer segments and reassembles data to ensure reliable delivery between devices.  
Refs: *Cisco Networking Essentials â€“ Ch.2, p.14*  

---

## ğŸ“Š Analytics Overview  

- For Students:  
  - Pre-test score  
  - AI-assigned level  
  - Post-test performance  
  - Topic strengths and weaknesses  

- For Instructors:  
  - Average class progress  
  - Distribution of learning levels  
  - Commonly missed topics  
  - Learning gain (pre â†’ post)  

---

## ğŸ³ Docker Setup  
The application runs in isolated containers for:  
- Next.js app  
- Supabase (PostgreSQL + `pgvector`)  
- Ollama for AI model serving  

---

## ğŸ”’ Privacy & Transparency  
- All inference runs locally using Ollama â€” no external API calls.  
- Every question and explanation cites a RAG reference, ensuring academic integrity.  
- If insufficient context is retrieved, the system automatically regenerates using additional references.  

---

